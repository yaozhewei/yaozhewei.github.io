---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---



About Me
======
Zhewei Yao is a senior researcher at Microsoft, working on efficient large scale training and inference. He obtained his Ph.D. degree from University of California at Berkeley, where he was a Ph.D. researcher in [BAIR](https://bair.berkeley.edu/), [RISELab](https://rise.cs.berkeley.edu/) ([former AMPLab](https://amplab.cs.berkeley.edu)), [BDD](https://deepdrive.berkeley.edu/), and [Math Department](https://math.berkeley.edu/). He was advised by [Michael Mahoney](https://www.stat.berkeley.edu/~mmahoney/), and he worked very closely with [Kurt Keutzer](https://people.eecs.berkeley.edu/~keutzer/). His research interest lies in computing statistics, optimization, and machine learning. Currently, he is interested in leveraging tools from randomized linear algebra to provide efficient and scalable solutions for large-scale optimization and learning problems. He is also working on the theory and application of deep learning. Before joining UC Berkeley, he received his B.S. in Math from [Zhiyuan Honor College](http://zhiyuan.sjtu.edu.cn/) at [Shanghai Jiao Tong University](http://en.sjtu.edu.cn/). Here is the [CV](http://yaozhewei.github.io/files/CV.pdf) (last update 10/04/2021).

Publications
======
## Conference
* <span style="color:blue">Q-ASR: Integer-only Zero-shot Quantization for Efficient Speech Recognition</span>.\\
S. Kim, A. Gholami, **Z. Yao**, A. Nrusimha, B. Zhai, T. Gao, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/2103.16827.pdf)\\
Accepted for publication, Proc. ICASSP 2022
* <span style="color:blue">How Much Can CLIP Benefit Vision-and-Language Tasks?</span>.\\
S. Shen, L. H. Li, H. Tan, M. Bansal, A. Rohrbach, K. Chang, **Z. Yao**, K Keutzer\\
[arXiv](https://arxiv.org/pdf/2107.06383.pdf)\\
Accepted for publication, Proc. ICLR 2022
* <span style="color:blue">Benchmarking Semi-supervised Federated Learning</span>.\\
Z. Zhang<sup>*</sup>, **Z. Yao<sup>*</sup>**, Y. Yang, Y. Yan, J. E. Gonzalez, and M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/2008.11364.pdf), [code](https://github.com/jhcknzzm/SSFL-Benchmarking-Semi-supervised-Federated-Learning)\\
Accepted for publication, Proc. IEEE BigData 2021
* <span style="color:blue">Hessian-Aware Pruning and Optimal Neural Implant</span>.\\
S. Yu<sup>*</sup>, **Z. Yao<sup>*</sup>**, A. Gholami<sup>*</sup>, Z. Dong<sup>*</sup>, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/2101.08940.pdf), [code](https://github.com/yaozhewei/hap)\\
Accepted for publication, Proc. WACV 2022
* <span style="color:blue">What’s Hidden in a One-layer Randomly Weighted Transformer?</span>.\\
S. Shen<sup>*</sup>, **Z. Yao<sup>*</sup>**,  D. Kiela, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/2101.08940.pdf), [code](https://github.com/yaozhewei/hap)\\
Accepted for publication, Proc. EMNLP 2021
* <span style="color:blue">ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training</span>.\\
J. Chen, L. Zheng, Z. Yao, D. Wang, I. Stoica, M. W. Mahoney, J. E. Gonzalez\\
[arXiv](https://arxiv.org/pdf/2104.14129.pdf)\\
Accepted for publication, Proc. ICML 2021 (Long Talk).
* <span style="color:blue">I-BERT: Integer-only BERT Quantization</span>.\\
S. Kim<sup>*</sup>, A. Gholami<sup>*</sup>, **Z. Yao<sup>*</sup>**, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/2101.01321.pdf), [code](https://github.com/kssteven418/I-BERT)\\
Accepted for publication, Proc. ICML 2021 (Long Talk).
* <span style="color:blue">HAWQ-V3: Dyadic Neural Network Quantization</span>.\\
**Z. Yao<sup>*</sup>**, Z. Dong<sup>*</sup>, Z. Zheng<sup>*</sup>, A. Gholami<sup>*</sup>, J. Yu, E. Tan, L. Wang, Q. Huang, Y. Wang, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/2011.10680.pdf), [code](https://github.com/Zhen-Dong/HAWQ)\\
Accepted for publication, Proc. ICML 2021 (Short Talk).
* <span style="color:blue">ADAHESSIAN: An Adaptive Second Order Optimizer for Machine Learning</span>.\\
**Z. Yao<sup>*</sup>**, A. Gholami<sup>*</sup>, S. Shen, K. Keutzer, and M. W. Mahoney, \\
[arXiv](https://arxiv.org/pdf/2006.00719.pdf), [code](https://github.com/amirgholami/adahessian)\\
Accepted for publication, Proc. AAAI 2021.
* <span style="color:blue">A Statistical Framework for Low-bitwidth Training of Deep Neural Networks</span>.\\
J. Chen, Y. Gai, **Z. Yao**, M. W. Mahoney, and J. E. GonZalez\\
[arXiv](https://arxiv.org/pdf/2010.14298.pdf), [code](https://github.com/cjf00000/StatQuant)\\
Accepted for publication, Proc. NeurIPS 2020.
* <span style="color:blue">MAF: Multimodal Alignment Framework for Weakly-Supervised Phrase Grounding</span>.\\
Q. Wang, H. Tan, S. Shen, M. W. Mahoney, and **Z. Yao**\\
[arXiv](https://arxiv.org/pdf/2010.05379.pdf), [code](https://github.com/qinzzz/Multimodal-Alignment-Framework)\\
Accepted for publication, Proc. EMNLP 2020.
* <span style="color:blue">PowerNorm: Rethinking Batch Normalization in Transformers</span>.\\
S. Shen<sup>*</sup>, **Z. Yao<sup>*</sup>**, A. Gholami, M. W. Mahoney, and K. Keutzer\\
[arXiv](https://arxiv.org/pdf/2003.07845.pdf), [code](https://github.com/sIncerass/powernorm)\\
Accepted for publication, Proc. ICML 2020.
* <span style="color:blue">ZeroQ: A Novel Zero Shot Quantization Framework</span>.\\
Y. Cai<sup>*</sup>, **Z. Yao<sup>*</sup>**, Z. Dong<sup>*</sup>, A. Gholami, M. W. Mahoney, and K. Keutzer\\
[arXiv](https://arxiv.org/pdf/2001.00281.pdf), [code](https://github.com/amirgholami/ZeroQ)\\
Accepted for publication, Proc. CVPR 2020.
* <span style="color:blue">PyHessian: Neural Networks Through the Lens of the Hessian</span>.\\
**Z. Yao<sup>*</sup>**, A. Gholami<sup>*</sup>, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1912.07145.pdf), [code](https://github.com/amirgholami/PyHessian)\\
Accepted for publication, Proc. IEEE BigData 2020.
* <span style="color:blue">HAWQ-V2: Hessian Aware trace-Weighted Quantization of Neural Networks</span>.\\
Z. Dong, **Z. Yao**, Y. Cai, D. Arfeen, A. Gholami, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/1911.03852.pdf), [code](https://github.com/Zhen-Dong/HAWQ)\\
Accepted for publication, Proc. NeurIPS 2020.
* <span style="color:blue">Q-BERT: Hessian Based Ultra Low Precision Quantization of BERT</span>.\\
S. Shen, Z. Dong, J. Ye, L. Ma, **Z. Yao**, A. Gholami, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/1909.05840.pdf)\\
Accepted for publication, Proc. AAAI 2020.
* <span style="color:blue">ANODEV2: A Coupled Neural ODE Evolution Framework</span>.\\
T. Zhang<sup>*</sup>, **Z. Yao<sup>*</sup>**, A. Gholami<sup>*</sup>, K. Keutzer, J. Gonzalez, G. Biros, and M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1906.04596.pdf), [code](https://github.com/amirgholami/anode)\\
Accepted for publication, Proc. NeurIPS 2019.
* <span style="color:blue">HAWQ: Hessian AWare Quantization of Neural Networks with Mixed-Precision</span>.\\
Z. Dong<sup>*</sup>, **Z. Yao<sup>*</sup>**, A. Gholami<sup>*</sup>, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/1905.03696.pdf), [code](https://github.com/Zhen-Dong/HAWQ)\\
Accepted for publication, Proc. ICCV 2019.
* <span style="color:blue">Inefficiency of K-FAC for Large Batch Size Training</span>.\\
L. Ma, G. Montague, J. Ye, **Z. Yao**, A. Gholami, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1903.06237.pdf)\\
Accepted for publication, Proc. AAAI 2020.
* <span style="color:blue">JumpReLU: A Retrofit Defense Strategy for Adversarial Attacks</span>.\\
N. B. Erichson<sup>*</sup>, **Z. Yao<sup>*</sup>**, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1904.03750.pdf)\\
Accepted for publication, Proc. ICPRAM 2020.
* <span style="color:blue">Trust Region Based Adversarial Attack on Neural Networks</span>.\\
**Z. Yao**, A. Gholami, P. Xu, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1812.06371.pdf), [code](https://github.com/amirgholami/TRAttack)\\
Accepted for publication, Proc. CVPR 2019.
* <span style="color:blue">Hessian-based Analysis of Large Batch Training and Robustness to Adversaries</span>.\\
**Z. Yao<sup>*</sup>**, A. Gholami<sup>*</sup>, Q. Lei, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1802.08241.pdf), [code](https://github.com/amirgholami/HessianFlow)\\
Accepted for publication, Proc. NIPS 2018.

## Journal
* <span style="color:blue">Shallow Learning for Fluid Flow Reconstruction with Limited Sensors and Limited Data</span>.\\
N. B. Erichson, L. Mathelin, **Z. Yao**, S. L. Brunton, M. W. Mahoney, J. N. Kutz\\
[arXiv](https://arxiv.org/pdf/1902.07358.pdf)\\
Accepted for publication, Proceedings of the Royal Society A.
* <span style="color:blue">Inexact non-convex Newton-type methods</span>.\\
**Z. Yao**, P. Xu, F. Roosta-Khorasani, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1802.06925.pdf), [code](https://github.com/yaozhewei/Inexact_Newton_Method)\\
Accepted for publication, INFORMS Journal on Optimization.
* <span style="color:blue">A hybrid adaptive MCMC algorithm in function spaces</span>.\\
Q. Zhou, Z. Hu, **Z. Yao**, J. Li\\
[arXiv](https://arxiv.org/pdf/1607.01458.pdf)\\
SIAM/ASA Journal on Uncertainty Quantification 5 (1), 621-639
* <span style="color:blue">On an adaptive preconditioned Crank–Nicolson MCMC algorithm for infinite dimensional Bayesian inference</span>.\\
Z. Hu, **Z. Yao**, J. Li\\
[arXiv](https://arxiv.org/pdf/1511.05838.pdf)\\
Journal of Computational Physics 332, 492-503
* <span style="color:blue"> A TV-Gaussian prior for infinite-dimensional Bayesian inverse problems and its numerical implementation</span>.\\
**Z. Yao**, Z. Hu, J. Li\\
[arXiv](https://arxiv.org/pdf/1510.05239.pdf)\\
Inverse Problems 32 (7), 075006 (Highlight Paper)
## Book Chapter
* <span style="color:blue">A Survey of Quantization Methods for Efficient Neural Network Inference</span>.\\
A. Gholami<sup>*</sup>, S. Kim<sup>*</sup>, Z. Dong<sup>*</sup>, **Z. Yao<sup>*</sup>**, M. W. Mahoney, K. Keutzer\\
[arXiv](https://arxiv.org/pdf/2103.13630.pdf)\\
Low-Power Computer Vision: Improving the Efficiency of Artificial Intelligence, 2021.

## Workshop
* <span style="color:blue">Parameter Re-Initialization through Cyclical Batch Scheduling</span>.\\
N. Mu<sup>*</sup>, **Z. Yao<sup>*</sup>**, A. Gholami, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1812.01216.pdf)\\
Accepted for publication, Proc. MLSYS Workshop at NIPS 2018
* <span style="color:blue">An Empirical Exploration of Gradient Correlations in Deep Learning</span>.\\
D. Rothchild, R. Fox, N. Golmant, J. Gonzalez, M. W. Mahoney, K. Rothauge, I. Stoica and **Z. Yao**\\
Integration of Deep Learning Theories, NeurIPS 2018

## Preprint and Technical Report
* <span style="color:blue">DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale</span>.\\
S. Rajbhandari, C. Li, **Z. Yao**, M. Zhang, R. Y. Aminabadi, A. A. Awan, J. Rasley, Y. He\\
[arXiv](https://arxiv.org/pdf/2201.05596.pdf)
* <span style="color:blue">Inexact Newton-CG Algorithms With Complexity Guarantees</span>.\\
**Z. Yao**, P. Xu, F. Roosta, S. J. Wright, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/2109.14016.pdf)
* <span style="color:blue">MLPruning: A Multilevel Structured Pruning Framework for Transformer-based Models</span>.\\
**Z. Yao**, L. Ma, S. Shen, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/2105.14636.pdf)
* <span style="color:blue">Residual Networks as Nonlinear Systems: Stability Analysis using Linearization</span>.\\
K. Rothauge, **Z. Yao**, Z. Hu, and M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1905.13386.pdf)
* <span style="color:blue">On the Computational Inefficiency of Large Batch Sizes for Stochastic Gradient Descent</span>.\\
N. Golmant, N. Vemuri, **Z. Yao**, V. Feinberg, A. Gholami, K. Rothauge, M. W. Mahoney, J. Gonzalez\\
[arXiv](https://arxiv.org/pdf/1811.12941.pdf)
* <span style="color:blue">Large batch size training of neural networks with adversarial training and second-order information</span>.\\
**Z. Yao<sup>*</sup>**, A. Gholami<sup>*</sup>, K. Keutzer, M. W. Mahoney\\
[arXiv](https://arxiv.org/pdf/1810.01021.pdf), [code](https://github.com/amirgholami/HessianFlow)

Selected Talks
======
* ICML'21 ([ICML](https://icml.cc/Conferences/2021/ScheduleMultitrack?event=10100))\\
Online (Jul, 2021)
* SIAM CSE'21: Beyond First Order Methods in Machine Learning Systems ([CSE](https://www.siam.org/conferences/cm/conference/cse21))\\
Online (Mar, 2021)
* AAAI'21 ([AAAI](https://aaai.org/Conferences/AAAI-21/))\\
Online (Feb, 2021)
* IEEE BigData'20 ([BigData](https://bigdataieee.org/BigData2020/))\\
Online (Dec, 2020), [slides](http://yaozhewei.github.io/files/pyhessian.pdf)
* Berkeley Real-time Intelligent Secure Explanaible Systems Lab Camp ([RiseLab](https://rise.cs.berkeley.edu/))\\
Online (Oct, 2020), [slides1](http://yaozhewei.github.io/files/adahessian.pdf) and [slides2](http://yaozhewei.github.io/files/pyhessian.pdf), [vedio](https://www.youtube.com/watch?v=sMDhXKqxfZc&list=PLTPaZLQlNIHo16Qq67CqWS6UKWrYREeKg&index=8)
* Fast.AI ([Fast.AI](https://www.fast.ai/))\\
Online (Oct, 2020), [slides](http://yaozhewei.github.io/files/adahessian.pdf), [vedio](https://www.youtube.com/watch?v=S87ancnZ0MM)
* Scalable Parallel Computing Lab ([SPCL](https://spcl.inf.ethz.ch/Bcast/))\\
Online (Oct, 2020), [slides](http://yaozhewei.github.io/files/adahessian.pdf), [vedio](https://youtu.be/AM9Bo8jLPpE)
* ICML'20 Workshop on Beyond First-Order Optimization Methods in Machine Learning ([Beyond](https://sites.google.com/view/optml-icml2020))\\
Online (July, 2020), [slides](http://yaozhewei.github.io/files/pyhessian.pdf), [vedio](https://icml.cc/virtual/2020/workshop/5737)
* Berkeley Real-time Intelligent Secure Explanaible Systems Lab Sponsor Retreat ([RiseLab](https://rise.cs.berkeley.edu/))\\
Tahoe Lake, CA, USA (May, 2020), [slides](http://yaozhewei.github.io/files/adahessian.pdf)
* NeurIPS'19 Workshop on Beyond First-Order Optimization Methods in Machine Learning ([Beyond](https://sites.google.com/site/optneurips19/))\\
Vancouver, Canada (December, 2019)
* DIMACS Workshop on Randomized Numerical Linear Algebra, Statistics, and Optimization ([DIMACS](http://dimacs.rutgers.edu/programs/sf/sf-optimization/))\\
Rutgers University, New Jersey, USA (September, 2019), [slides](http://yaozhewei.github.io/files/NLA.pdf)
* Computer Vision Panel ([IJCAI](https://www.ijcai19.org/)) \\
Macau, China (August, 2019), [slides](http://yaozhewei.github.io/files/ANODE.pdf)
* Randomized Algorithms for Optimization Problems in Statistics ([JSM](https://ww2.amstat.org/meetings/jsm/2019/onlineprogram/ActivityDetails.cfm?sessionid=217975))\\
Colorado Convention Center, Denver, Colorado, USA (July, 2019), [slides](http://yaozhewei.github.io/files/JSM.pdf)
* Berkeley Scientific Computing and Matrix Computations Seminar ([Link](https://math.berkeley.edu/~mgu/LAPACKSeminar.htm))\\
Berkeley, CA, USA (November, 2018), [slides](http://yaozhewei.github.io/files/absa.pdf)
* Berkeley Real-time Intelligent Secure Explanaible Systems Lab Sponsor Retreat ([RiseLab](https://rise.cs.berkeley.edu/))\\
Tahoe Lake, CA, USA (August, 2018), [slides](http://yaozhewei.github.io/files/absa.pdf)

Teaching
======
* [Stat 89A](https://www.stat.berkeley.edu/~mmahoney/s18-lads/), Spring 2018
* [Math 16A](https://math.berkeley.edu/~apaulin/16B_001%20(Spring%202017).html), Spring 2017
* Math 16A, Fall 2016
